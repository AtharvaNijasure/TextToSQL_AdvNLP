{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc49d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22434,
     "status": "ok",
     "timestamp": 1683756039554,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "44dc49d1",
    "outputId": "f71e642f-cc11-4720-847d-9983cfafdaad"
   },
   "outputs": [],
   "source": [
    "# # MOUNTING GOOGLE DRIVE\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "\n",
    "# wd = '/content/drive/MyDrive/CS 685/cs685_project/notebooks'\n",
    "# print(os.listdir(wd))\n",
    "# os.chdir(wd)\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EOrjkzvAqCng",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28261,
     "status": "ok",
     "timestamp": 1683756067809,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "EOrjkzvAqCng",
    "outputId": "a12095b7-7146-43c2-e55b-2153180dfe64",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tokenizers\n",
    "# !pip install transformers\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9ce01e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13533,
     "status": "ok",
     "timestamp": 1683756081335,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "ee9ce01e",
    "outputId": "754fbbbc-1c71-4490-81a9-e08292caace6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "from load_dataset import Text2SQLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tokenizers import AddedToken\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import BertModel, T5ForConditionalGeneration, T5Tokenizer, BertTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4f5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.config.is_encoder_decoder = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e05bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.config.decoder_start_token_id, model_2.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc843bcd",
   "metadata": {
    "id": "bc843bcd"
   },
   "source": [
    "## Need to replace BERT as GNN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17abad9d",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683756081335,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "17abad9d"
   },
   "outputs": [],
   "source": [
    "# FOR PRINTING INTERMEDIATE TORCH SIZES\n",
    "DEBUG_FLAG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4921e160",
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1683756383738,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "4921e160"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, bert_hidden_size, t5_hidden_size, max_input_length, \n",
    "                 max_output_length, bert_model, t5_model, batch_size):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "        self.t5_hidden_size = t5_hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        self.t5 = T5ForConditionalGeneration.from_pretrained(t5_model)\n",
    "#         self.linear = nn.Linear(bert_hidden_size, t5_hidden_size)\n",
    "        self.linear = nn.Linear(bert_hidden_size, max_input_length*t5_hidden_size)\n",
    "    \n",
    "\n",
    "    def forward(self, input_ids, input_mask,\n",
    "                decoder_input_ids, decoder_attention_mask):\n",
    "        \n",
    "        # Encode input with BERT\n",
    "        _, bert_output = self.bert(input_ids=input_ids, attention_mask=input_mask, return_dict=False)\n",
    "        \n",
    "        if DEBUG_FLAG: print(f\"bert_output - {bert_output.size()}\")\n",
    "        \n",
    "        # Transform BERT output to T5 input shape\n",
    "        t5_input = self.linear(bert_output)\n",
    "        if DEBUG_FLAG: print(f\"bert_output linear - {t5_input.size()}\")\n",
    "        \n",
    "#         t5_input = t5_input.unsqueeze(1).repeat(1, self.max_output_length, 1)\n",
    "#         if DEBUG_FLAG: print(f\"bert_output linear unsqueeze - {t5_input.size()}\")\n",
    "        \n",
    "        t5_input = t5_input.view(self.batch_size, self.max_input_length, self.t5_hidden_size)\n",
    "        t5_input = t5_input.unsqueeze(0)\n",
    "        if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()}\")\n",
    "        \n",
    "#         t5_outputs = self.t5(decoder_input_ids=decoder_input_ids,\n",
    "#                              decoder_attention_mask=decoder_attention_mask,\n",
    "#                              encoder_outputs=t5_input\n",
    "#                             )\n",
    "#         if DEBUG_FLAG: print(f\"t5_input logits - {(t5_outputs.logits).size()}\")\n",
    "#         return t5_outputs.logits\n",
    "    \n",
    "        t5_outputs = self.t5(labels=decoder_input_ids,\n",
    "                             decoder_attention_mask=decoder_attention_mask,\n",
    "                             encoder_outputs=t5_input,\n",
    "                             return_dict = True\n",
    "                            )\n",
    "        \n",
    "        if DEBUG_FLAG: print(f\"t5_input - {type(t5_outputs)}\")\n",
    "        return t5_outputs\n",
    "\n",
    "    def predict(self, input_ids, input_mask, batch_size, t5_tokenizer):\n",
    "        \n",
    "        _, bert_output = self.bert(input_ids=input_ids, attention_mask=input_mask, return_dict=False)\n",
    "        if DEBUG_FLAG: print(f\"bert_output - {bert_output.size()}\")\n",
    "        \n",
    "        # Transform BERT output to T5 input shape\n",
    "        t5_input = self.linear(bert_output)\n",
    "        if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()} - {t5_input}\")\n",
    "        t5_input = t5_input.view(batch_size, self.max_input_length, self.t5_hidden_size)\n",
    "        t5_input = t5_input.unsqueeze(0)\n",
    "        if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()} - {t5_input}\")\n",
    "            \n",
    "        t5_input = t5_input.to(torch.LongTensor) #int64)\n",
    "            \n",
    "#         t5_outputs = self.t5.generate(t5_input, max_length = 127)\n",
    "                       \n",
    "        #######################################\n",
    "        \n",
    "#         # Generate initial input for T5 decoder\n",
    "        start_token = t5_tokenizer.pad_token_id\n",
    "        \n",
    "#         decoder_input_ids = torch.tensor([start_token] * batch_size).unsqueeze(0)\n",
    "#         decoder_attention_mask = torch.tensor([1] * batch_size).unsqueeze(0)\n",
    "        \n",
    "        decoder_input_ids = torch.tensor([start_token]).unsqueeze(0)\n",
    "        decoder_attention_mask = torch.tensor([1]).unsqueeze(0)\n",
    "    \n",
    "#         decoder_input_ids = decoder_input_ids.view(decoder_input_ids.shape[1],\n",
    "#                                                    decoder_input_ids.shape[0])\n",
    "#         decoder_attention_mask = decoder_attention_mask.view(decoder_attention_mask.shape[1],\n",
    "#                                                              decoder_attention_mask.shape[0])\n",
    "        \n",
    "        print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "        print(f\"decoder_attention_mask - {decoder_attention_mask.size()}\")\n",
    "        \n",
    "        print(f\"initial decoder_input_ids - {decoder_input_ids}\")\n",
    "        # Use the model to get output logits\n",
    "        # Predict the output\n",
    "        with torch.no_grad():\n",
    "            for i in range(50):  # Maximum length of generated sequence\n",
    "                t5_outputs = self.t5(decoder_input_ids=decoder_input_ids,\n",
    "                                     decoder_attention_mask=decoder_attention_mask,\n",
    "                                     encoder_outputs=t5_input)\n",
    "#                 print(f\"t5_outputs - {t5_outputs}\")\n",
    "                print(f\"t5_outputs logits - {(t5_outputs.logits).size()}\")\n",
    "    \n",
    "                next_token_logits = t5_outputs.logits[:, -1, :]\n",
    "                print(f\"next_token_logits - {next_token_logits.size()}\")\n",
    "            \n",
    "#                 next_token_id = torch.argmax(next_token_logits, dim=-1)\n",
    "                next_token_id = next_token_logits.argmax(1)\n",
    "#                 print(f\"next_token_id - {next_token_id.size()}\")\n",
    "#                 print(f\"next_token_id.unsqueeze(-1) - {next_token_id.unsqueeze(-1).size()}\")\n",
    "                decoder_input_ids = torch.cat([decoder_input_ids, next_token_id.unsqueeze(-1)], dim=-1)\n",
    "                decoder_attention_mask = torch.cat([decoder_attention_mask,\n",
    "                                                    torch.ones_like(next_token_id.unsqueeze(-1))], dim=-1)\n",
    "\n",
    "                if next_token_id == t5_tokenizer.eos_token_id:\n",
    "                    break\n",
    "                \n",
    "                print(f\"pred decoder_input_ids - {decoder_input_ids}\")\n",
    "                \n",
    "#                 break\n",
    "        \n",
    "        # generated_text\n",
    "        t5_outputs = t5_tokenizer.decode(decoder_input_ids.squeeze(), skip_special_tokens=True)\n",
    "        #######################################\n",
    "            \n",
    "#         # Generate initial input for T5 decoder\n",
    "#         start_token = t5_tokenizer.pad_token_id\n",
    "        \n",
    "\n",
    "#         decoder_input_ids = torch.tensor([start_token] * batch_size).unsqueeze(0)\n",
    "#         decoder_attention_mask = torch.tensor([1] * batch_size).unsqueeze(0)\n",
    "    \n",
    "#         decoder_input_ids = decoder_input_ids.view(decoder_input_ids.shape[1],\n",
    "#                                                    decoder_input_ids.shape[0])\n",
    "#         decoder_attention_mask = decoder_attention_mask.view(decoder_attention_mask.shape[1],\n",
    "#                                                              decoder_attention_mask.shape[0])\n",
    "        \n",
    "#         print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "#         print(f\"decoder_attention_mask - {decoder_attention_mask.size()}\")\n",
    "        \n",
    "#         # Use the model to get output logits\n",
    "#         with torch.no_grad():\n",
    "#             t5_outputs = self.forward(input_ids, input_mask,\n",
    "#                                       decoder_input_ids, decoder_attention_mask)\n",
    "            \n",
    "        #######################################\n",
    "        # Encode input with BERT\n",
    "#         _, bert_output = self.bert(input_ids=input_ids, attention_mask=input_mask, return_dict=False)\n",
    "        \n",
    "#         if DEBUG_FLAG: print(f\"bert_output - {bert_output.size()}\")\n",
    "        \n",
    "#         # Transform BERT output to T5 input shape\n",
    "#         t5_input = self.linear(bert_output)\n",
    "#         t5_input = t5_input.unsqueeze(1).repeat(1, self.max_output_length, 1)\n",
    "\n",
    "#         t5_input = t5_input.unsqueeze(0)\n",
    "#         if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()}\")\n",
    "        \n",
    "# #         t5_outputs = self.t5(decoder_input_ids=decoder_input_ids,\n",
    "# #                              decoder_attention_mask=decoder_attention_mask,\n",
    "# #                              encoder_outputs=t5_input\n",
    "# #                             )\n",
    "        \n",
    "#         t5_outputs = self.t5.generate(input_ids=t5_input)\n",
    "\n",
    "        #######################################\n",
    "        \n",
    "#         # Encode input with BERT\n",
    "#         _, bert_output = self.bert(input_ids=input_ids, attention_mask=input_mask, return_dict=False)\n",
    "        \n",
    "#         if DEBUG_FLAG: print(f\"bert_output - {bert_output.size()}\")\n",
    "        \n",
    "#         # Transform BERT output to T5 input shape\n",
    "#         t5_input = self.linear(bert_output)\n",
    "#         t5_input = t5_input.unsqueeze(1).repeat(1, self.max_output_length, 1)\n",
    "\n",
    "#         t5_input = t5_input.unsqueeze(0)\n",
    "#         if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()}\")\n",
    "        \n",
    "#         t5_outputs = self.t5(encoder_outputs=t5_input)\n",
    "        \n",
    "#         if DEBUG_FLAG: print(f\"t5_input logits - {(t5_outputs).size()}\")\n",
    "        \n",
    "        return t5_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e519d2d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1683756664817,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "e519d2d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_filepath, batch_size, bert_hidden_size, t5_hidden_size, lr, num_epochs,\n",
    "         max_input_length, max_output_length, bert_model, t5_model):\n",
    "    \n",
    "    sub_folder_name = f\"BERT_T5_lr{lr}_bs{batch_size}_{bert_model}_{t5_model}\"\n",
    "    models_directory = f\"models/{sub_folder_name}\"\n",
    "\n",
    "    if not os.path.isdir(models_directory):\n",
    "        os.makedirs(models_directory)\n",
    "        \n",
    "    # TENSORBOARD\n",
    "    writer = SummaryWriter(f'tb/loss_plot/{sub_folder_name}')\n",
    "    \n",
    "    train_dataset = Text2SQLDataset(\n",
    "            dir_ = train_filepath,\n",
    "            mode = \"train\")\n",
    "\n",
    "    train_dataloder = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size = batch_size, \n",
    "            shuffle = True,\n",
    "            collate_fn = lambda x: x,\n",
    "            drop_last = True\n",
    "        )\n",
    "    \n",
    "    print(f\"Number of batches - {len(train_dataloder)}\")\n",
    "\n",
    "    # Define BERT and T5 tokenizers\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "    print(f\"Tokenizers loaded\")\n",
    "\n",
    "    model = EncoderDecoder(bert_hidden_size, t5_hidden_size, \n",
    "                           max_input_length, max_output_length,\n",
    "                           bert_model, t5_model, batch_size).to(device)\n",
    "    print(f\"Model loaded\")\n",
    "#     print(f\"{model.config.decoder_start_token_id}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    print(f\"Otimizer - Adam\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=t5_tokenizer.pad_token_id)\n",
    "    print(f\"CrossEntropyLoss initialized\")\n",
    "    \n",
    "    # initialize array of losses \n",
    "    losses = {'train': {}, \"val\": {}}\n",
    "\n",
    "    # for epoch in range(num_epochs):\n",
    "    with trange(num_epochs) as tr:\n",
    "        for epoch in tr:\n",
    "            \n",
    "            # Train the model\n",
    "            model.train()\n",
    "            \n",
    "            batch_loss = 0\n",
    "            \n",
    "            for idx, batch in enumerate(train_dataloder):\n",
    "\n",
    "                batch_inputs = [data[0] for data in batch]\n",
    "                batch_sqls = [data[1] for data in batch]\n",
    "\n",
    "                if DEBUG_FLAG:\n",
    "                    if epoch == 0 and idx == 0:\n",
    "                        print(f\"batch_inputs - {type(batch_inputs)} {len(batch_inputs)}\")\n",
    "                        print(f\"batch_sqls - {type(batch_sqls)} {len(batch_sqls)}\")\n",
    "                        \n",
    "#                 for temp_i, temp in enumerate(batch_inputs):\n",
    "#                     print(f\"batch_inputs - {batch_inputs[temp_i]}\")\n",
    "#                     print(f\"batch_sqls - {batch_sqls[temp_i]}\")\n",
    "\n",
    "                tokenized_inputs = bert_tokenizer(batch_inputs,\n",
    "                                                  add_special_tokens=True,\n",
    "                                                  padding=\"max_length\", #True,\n",
    "                                                  max_length=max_input_length,\n",
    "                                                  #pad_to_max_length=True,\n",
    "                                                  return_tensors='pt',\n",
    "                                                  truncation=True)\n",
    "\n",
    "                encoder_input_ids = tokenized_inputs[\"input_ids\"].to(device)\n",
    "                encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "#                 print(f\"encoder_input_ids - {encoder_input_ids}\")\n",
    "                tokenized_outputs = t5_tokenizer(batch_sqls,\n",
    "                                                 add_special_tokens=True,\n",
    "                                                 padding=\"max_length\", #True,\n",
    "                                                 max_length=max_output_length,\n",
    "                                                 #pad_to_max_length=True,\n",
    "                                                 return_tensors='pt',\n",
    "                                                 truncation=True)\n",
    "\n",
    "\n",
    "                decoder_input_ids = tokenized_outputs[\"input_ids\"].to(device)\n",
    "                # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "                decoder_input_ids[decoder_input_ids == t5_tokenizer.pad_token_id] = -100\n",
    "                decoder_attention_mask = tokenized_outputs[\"attention_mask\"].to(device)\n",
    "#                 labels = None #tokenized_outputs[\"attention_mask\"].to(device)\n",
    "\n",
    "#                 print(f\"decoder_input_ids - {decoder_input_ids}\")\n",
    "\n",
    "                if DEBUG_FLAG and epoch == 0 and idx == 0:\n",
    "                    print(f\"encoder_input_ids - {encoder_input_ids.size()}\")\n",
    "                    print(f\"encoder_input_attention_mask - {encoder_input_attention_mask.size()}\")\n",
    "                    print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "                    print(f\"decoder_attention_mask - {decoder_attention_mask.size()}\")\n",
    "\n",
    "                # Clear gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                model_output = model(encoder_input_ids,\n",
    "                               encoder_input_attention_mask,\n",
    "                               decoder_input_ids,\n",
    "                               decoder_attention_mask)\n",
    "#                                labels=labels)\n",
    "                \n",
    "                output = model_output[\"logits\"]\n",
    "#                 print(f\"output - {output.size()}\")\n",
    "#                 print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "                \n",
    "                output_resize = output.view(output.shape[0]*output.shape[1], output.shape[2])\n",
    "                decoder_input_ids_resize = decoder_input_ids.view(decoder_input_ids.shape[0]*decoder_input_ids.shape[1])\n",
    "                \n",
    "#                 print(f\"output_resize - {output_resize.size()}\")\n",
    "#                 print(f\"decoder_input_ids_resize - {decoder_input_ids_resize.size()}\")\n",
    "                    \n",
    "#                 loss = criterion(output_resize, decoder_input_ids_resize)\n",
    "#                 batch_loss += loss.item()\n",
    "                \n",
    "#                 print(f\"output - {model_output}\")\n",
    "                loss = model_output[\"loss\"]\n",
    "                batch_loss += loss\n",
    "                \n",
    "#                 predicted_classes = torch.argmax(output_resize, dim=-1)\n",
    "                \n",
    "#                 print(f\"output_resize - {predicted_classes.size} - {predicted_classes}\")\n",
    "#                 print(f\"decoder_input_ids_resize - {decoder_input_ids_resize}\")\n",
    "\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                break\n",
    "                \n",
    "            batch_loss /= len(train_dataloder) \n",
    "            losses['train'][epoch] = f\"{batch_loss:.3f}\"\n",
    "            #progress bar \n",
    "            tr.set_postfix({\"epoch_num\":epoch,\n",
    "                            \"loss\":f\"{batch_loss:.10f}\"})\n",
    "            \n",
    "            with open(os.path.join(models_directory, \"loss.json\"), 'w') as f:\n",
    "                json.dump(losses, f)\n",
    "            \n",
    "            writer.add_scalar('Training loss', batch_loss, global_step=epoch+1)\n",
    "            # save models\n",
    "            if (epoch > 3 and epoch % 5 == 0):\n",
    "                torch.save(model, os.path.join(models_directory, f\"model_{epoch}\"))\n",
    "    torch.save(model, os.path.join(models_directory, f\"model_last_{epoch}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4444e046",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420541,
     "status": "ok",
     "timestamp": 1683757085355,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "4444e046",
    "outputId": "279d8873-1753-4cf1-9622-eaab0b82a39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches - 3152\n",
      "Tokenizers loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Otimizer - Adam\n",
      "CrossEntropyLoss initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                   | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_inputs - <class 'list'> 2\n",
      "batch_sqls - <class 'list'> 2\n",
      "encoder_input_ids - torch.Size([2, 43])\n",
      "encoder_input_attention_mask - torch.Size([2, 43])\n",
      "decoder_input_ids - torch.Size([2, 127])\n",
      "decoder_attention_mask - torch.Size([2, 127])\n",
      "bert_output - torch.Size([2, 768])\n",
      "bert_output linear - torch.Size([2, 22016])\n",
      "t5_input - torch.Size([1, 2, 43, 512])\n",
      "input_shape - torch.Size([2, 127])\n",
      "t5_input - <class 'transformers.modeling_outputs.Seq2SeqLMOutput'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                   | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define hyperparameters\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_filepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/resdsql_pre/preprocessed_dataset_train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#32\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbert_hidden_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mt5_hidden_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#300\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_input_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m43\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_output_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m127\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m      \u001b[49m\u001b[43mt5_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt5-small\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 138\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_filepath, batch_size, bert_hidden_size, t5_hidden_size, lr, num_epochs, max_input_length, max_output_length, bert_model, t5_model)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#                 predicted_classes = torch.argmax(output_resize, dim=-1)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m                 \n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#                 print(f\"output_resize - {predicted_classes.size} - {predicted_classes}\")\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#                 print(f\"decoder_input_ids_resize - {decoder_input_ids_resize}\")\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m                 \u001b[38;5;66;03m# backpropagation\u001b[39;00m\n\u001b[1;32m    137\u001b[0m                 loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 138\u001b[0m                 \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    142\u001b[0m             batch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloder) \n",
      "File \u001b[0;32m~/Aishwarya/Learning/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Aishwarya/Learning/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/Aishwarya/Learning/venv/lib/python3.11/site-packages/torch/optim/adam.py:132\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    129\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Aishwarya/Learning/venv/lib/python3.11/site-packages/torch/optim/adam.py:92\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m     86\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.\u001b[39m)\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m     94\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "train(train_filepath = \"../data/resdsql_pre/preprocessed_dataset_train.json\",\n",
    "      batch_size = 2, #32\n",
    "      bert_hidden_size = 768,\n",
    "      t5_hidden_size = 512,\n",
    "      lr = 1e-4,\n",
    "      num_epochs = 1, #300\n",
    "      max_input_length = 43,\n",
    "      max_output_length = 127,\n",
    "      bert_model = 'bert-base-uncased',\n",
    "      t5_model = 't5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa55e8",
   "metadata": {
    "id": "bbaa55e8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21797c26",
   "metadata": {
    "id": "083df0db"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b6b910f",
   "metadata": {
    "id": "6b6b910f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (t5): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=22016, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "model_path = os.path.join(os.getcwd(), \"models/BERT_T5_lr0.0001_bs32_bert-base-uncased_t5-small_v2/model_45\")\n",
    "\n",
    "model2 = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "353361ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "dev_filepath = \"../data/resdsql_pre/preprocessed_dataset_test.json\"\n",
    "batch_size = 1\n",
    "max_input_length = 43\n",
    "bert_model = 'bert-base-uncased'\n",
    "t5_model = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c38bf753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_ids - torch.Size([1, 43])\n",
      "encoder_input_attention_mask - torch.Size([1, 43])\n",
      "bert_output - torch.Size([1, 768])\n",
      "t5_input - torch.Size([1, 22016]) - tensor([[-0.3868, -0.0247, -0.4702,  ...,  0.0945, -0.0294,  0.0712]])\n",
      "t5_input - torch.Size([1, 1, 43, 512]) - tensor([[[[-0.3868, -0.0247, -0.4702,  ..., -0.2077, -0.2603, -0.1218],\n",
      "          [-0.3328, -0.0058,  0.0729,  ..., -0.2861,  0.0093, -0.0350],\n",
      "          [-0.2480, -0.2029,  0.1298,  ...,  0.0912,  0.0502, -0.1692],\n",
      "          ...,\n",
      "          [ 0.1496,  0.0186, -0.2902,  ...,  0.1612,  0.1298, -0.0306],\n",
      "          [-0.0021,  0.1038,  0.1240,  ..., -0.0027, -0.1364, -0.1173],\n",
      "          [-0.0241, -0.0827, -0.0097,  ...,  0.0945, -0.0294,  0.0712]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_l/w4llrmnx2fd53tjbtdxfl65r0000gn/T/ipykernel_52827/4112407450.py:65: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:367.)\n",
      "  t5_input = t5_input.to(torch.LongTensor) #int64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "to() received an invalid combination of arguments - got (torch.tensortype), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_input_attention_mask - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder_input_attention_mask\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 48\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt5_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt5_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#         model_outputs = model_outputs.view(len(batch_inputs), opt.num_return_sequences, model_outputs.shape[1])\u001b[39;00m\n\u001b[1;32m     52\u001b[0m         \n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#         predict_sqls += decode_sqls(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#                                     batch_tc_original\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#                                     )\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 65\u001b[0m, in \u001b[0;36mEncoderDecoder.predict\u001b[0;34m(self, input_ids, input_mask, batch_size, t5_tokenizer)\u001b[0m\n\u001b[1;32m     62\u001b[0m         t5_input \u001b[38;5;241m=\u001b[39m t5_input\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m DEBUG_FLAG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5_input - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt5_input\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt5_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m         t5_input \u001b[38;5;241m=\u001b[39m \u001b[43mt5_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#int64)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#         t5_outputs = self.t5.generate(t5_input, max_length = 127)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m                        \n\u001b[1;32m     69\u001b[0m         \u001b[38;5;66;03m#######################################\u001b[39;00m\n\u001b[1;32m     70\u001b[0m         \n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#         # Generate initial input for T5 decoder\u001b[39;00m\n\u001b[1;32m     72\u001b[0m         start_token \u001b[38;5;241m=\u001b[39m t5_tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n",
      "File \u001b[0;32m~/Aishwarya/Learning/venv/lib/python3.11/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mTypeError\u001b[0m: to() received an invalid combination of arguments - got (torch.tensortype), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# initialize tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "\n",
    "# if isinstance(tokenizer, T5TokenizerFast):\n",
    "#     tokenizer.add_tokens([AddedToken(\" <=\"), AddedToken(\" <\")])\n",
    "\n",
    "dev_dataset = Text2SQLDataset(\n",
    "            dir_ = dev_filepath,\n",
    "            mode = \"train\")\n",
    "\n",
    "dev_dataloder = DataLoader(\n",
    "        dev_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = False,\n",
    "        collate_fn = lambda x: x,\n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "# initialize model\n",
    "\n",
    "model2.eval()\n",
    "predict_sqls = []\n",
    "# for batch in tqdm(dev_dataloder):\n",
    "for idx, batch in enumerate(dev_dataloder):\n",
    "    batch_inputs = [data[0] for data in batch]\n",
    "    batch_db_ids = [data[1] for data in batch]\n",
    "    batch_tc_original = [data[2] for data in batch]\n",
    "\n",
    "    tokenized_inputs = bert_tokenizer(batch_inputs,\n",
    "                                      add_special_tokens=True,\n",
    "                                      padding=\"max_length\", #True,\n",
    "                                      max_length=max_input_length,\n",
    "                                      #pad_to_max_length=True,\n",
    "                                      return_tensors='pt',\n",
    "                                      truncation=True)\n",
    "\n",
    "    encoder_input_ids = tokenized_inputs[\"input_ids\"].to(device)\n",
    "    encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    print(f\"encoder_input_ids - {encoder_input_ids.size()}\")\n",
    "    print(f\"encoder_input_attention_mask - {encoder_input_attention_mask.size()}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_outputs = model2.predict(encoder_input_ids, encoder_input_attention_mask,\n",
    "                                       batch_size=1, t5_tokenizer=t5_tokenizer)\n",
    "\n",
    "#         model_outputs = model_outputs.view(len(batch_inputs), opt.num_return_sequences, model_outputs.shape[1])\n",
    "        \n",
    "#         predict_sqls += decode_sqls(\n",
    "#                                     opt.db_path, \n",
    "#                                     model_outputs, \n",
    "#                                     batch_db_ids, \n",
    "#                                     batch_inputs, \n",
    "#                                     tokenizer, \n",
    "#                                     batch_tc_original\n",
    "#                                     )\n",
    "    break\n",
    "\n",
    "\n",
    "# new_dir = \"/\".join(opt.output.split(\"/\")[:-1]).strip()\n",
    "# if new_dir != \"\":\n",
    "#     os.makedirs(new_dir, exist_ok = True)\n",
    "\n",
    "# # save results\n",
    "# with open(opt.output, \"w\", encoding = 'utf-8') as f:\n",
    "#     for pred in predict_sqls:\n",
    "#         f.write(pred + \"\\n\")\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(\"Text-to-SQL inference spends {}s.\".format(end_time-start_time))\n",
    "\n",
    "# if opt.mode == \"eval\":\n",
    "#     # initialize evaluator\n",
    "#     evaluator = EvaluateTool()\n",
    "#     evaluator.register_golds(opt.original_dev_filepath, opt.db_path)\n",
    "#     spider_metric_result = evaluator.evaluate(predict_sqls)\n",
    "#     print('exact_match score: {}'.format(spider_metric_result[\"exact_match\"]))\n",
    "#     print('exec score: {}'.format(spider_metric_result[\"exec\"]))\n",
    "\n",
    "#     return spider_metric_result[\"exact_match\"], spider_metric_result[\"exec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf57136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
